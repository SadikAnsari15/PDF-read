{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16c25be-b773-433c-b9a0-93bfe796d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "import os \n",
    "import requests \n",
    "from pdf2image import convert_from_bytes \n",
    "from PIL import Image \n",
    "import base64 \n",
    "import json\n",
    "import pytesseract\n",
    "from io import BytesIO \n",
    "import pandas as pd\n",
    "\n",
    "def clean(dict_variable):\n",
    "    return next(iter(dict_variable.values()))\n",
    "    \n",
    "client = OpenAI(api_key='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f695eebd-f133-4f4d-94d3-c92ca82de18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # For Windows\n",
    "\n",
    "# OCR function to extract text from image\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "# URL of the image\n",
    "# image_url = \"https://crm.autocarloan.co.uk/images/66e192f2f12a94a822acbbc1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "527c995b-f82e-4d99-8987-bb0b9141c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "U K DRIVING LICENCE\n",
      "\n",
      "COLOMBARI\n",
      "MR SAMUEL CHARLES\n",
      "\n",
      "20.02.1998 UNITED KINGDOM\n",
      "08.02.2022 4c. DVLA\n",
      "07.02.2027\n",
      "COLOM902208SC9BH 33\n",
      "\n",
      "Seu\n",
      "\n",
      "25 SOUTHGATE, HORNSEA, HU18 1RE\n",
      "\n",
      "AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure that Tesseract is correctly installed and the path is set (for Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update path as needed\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Extract text using pytesseract\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "# Path to the local image file\n",
    "image_path = \"F:/wesi/5.jpg\"\n",
    "\n",
    "try:\n",
    "    # Open the local image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    \n",
    "    # Output the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "59ff32fd-caa2-4700-b1d7-87123b3d19ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U K DRIVING LICENCE\\n\\nCOLOMBARI\\nMR SAMUEL CHARLES\\n\\n20.02.1998 UNITED KINGDOM\\n08.02.2022 4c. DVLA\\n07.02.2027\\nCOLOM902208SC9BH 33\\n\\nSeu\\n\\n25 SOUTHGATE, HORNSEA, HU18 1RE\\n\\nAM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\\n\\n'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "48371fdd-eb92-4392-851a-22584e5b23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"Seu\" from the text\n",
    "extracted_text = extracted_text.replace(\"Seu\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b00444f7-5f07-4742-b633-8863def8eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into lines for easier parsing\n",
    "lines = extracted_text.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b9e83ab4-5770-4a71-86ad-c6326d956c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty strings from the list\n",
    "lines = [line for line in lines if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4a5f0767-5f13-4219-a929-f0df0f5fefe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U K DRIVING LICENCE',\n",
       " 'COLOMBARI',\n",
       " 'MR SAMUEL CHARLES',\n",
       " '20.02.1998 UNITED KINGDOM',\n",
       " '08.02.2022 4c. DVLA',\n",
       " '07.02.2027',\n",
       " 'COLOM902208SC9BH 33',\n",
       " '25 SOUTHGATE, HORNSEA, HU18 1RE',\n",
       " 'AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "89892074-43b7-4058-a88c-2bf3fe0ef152",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[203], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m surname \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      3\u001b[0m first_name \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# Remove \"MR \" from the name\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m date_of_birth, place_of_birth \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m UNITED KINGDOM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m date_of_issue, issuing_authority \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 4c. \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m expiry_date \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Parsing the text based on known structure\n",
    "surname = lines[2].strip()\n",
    "first_name = lines[3].strip()  # Remove \"MR \" from the name\n",
    "date_of_birth, place_of_birth = lines[5].strip().split(' UNITED KINGDOM')\n",
    "date_of_issue, issuing_authority = lines[6].strip().split(' 4c. ')\n",
    "expiry_date = lines[7].strip()\n",
    "driver_number = lines[8].strip()\n",
    "address = lines[10].strip()\n",
    "entitlements = lines[12].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "30ea0e1e-d9da-4dcd-983b-b263c469fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "    \"country\": place_of_birth,\n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": place_of_birth.strip(),\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5b5467e1-6991-4be4-a633-b98a5e3348b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"\",\n",
      "    \"surname\": \"COLOMBARI\",\n",
      "    \"first_name\": \"MR SAMUEL CHARLES\",\n",
      "    \"date_of_birth\": \"20.02.1998\",\n",
      "    \"place_of_birth\": \"\",\n",
      "    \"date_of_issue\": \"08.02.2022\",\n",
      "    \"issuing_authority\": \"DVLA\",\n",
      "    \"expiry_date\": \"07.02.2027\",\n",
      "    \"driver_number\": \"COLOM902208SC9BH 33\",\n",
      "    \"address\": \"\",\n",
      "    \"entitlements\": \"25 SOUTHGATE, HORNSEA, HU18 1RE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6ea02-4d60-443a-ba49-fbde5ed39901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df2f2a-a077-4489-a0a1-57c41ae74b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29571225-5cae-4696-afc1-e100bf99b5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45a633fc-8f63-42ed-8147-6029a2cc8c6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m surname \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     14\u001b[0m first_name \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMR \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Remove \"MR \" from the name\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m date_of_birth, place_of_birth \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m UNITED KINGDOM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m date_of_issue, issuing_authority \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 4c. \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m expiry_date \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Split the text into lines for easier parsing\n",
    "#lines = extracted_text.strip().split('\\n')\n",
    "\n",
    "# Identify the country from the text\n",
    "country = \"Unknown\"  # Default value\n",
    "for line in lines:\n",
    "    if \"UNITED KINGDOM\" in line.upper():  # Look for 'UNITED KINGDOM' in any line\n",
    "        country = \"United Kingdom\"\n",
    "    elif \"U K\" in line.upper():\n",
    "        country = \"United Kingdom\"\n",
    "\n",
    "# Parsing the text based on known structure\n",
    "surname = lines[2].strip()\n",
    "first_name = lines[3].strip().replace('MR ', '')  # Remove \"MR \" from the name\n",
    "date_of_birth, place_of_birth = lines[5].strip().split(' UNITED KINGDOM')\n",
    "date_of_issue, issuing_authority = lines[6].strip().split(' 4c. ')\n",
    "expiry_date = lines[7].strip()\n",
    "driver_number = lines[8].strip()\n",
    "address = lines[10].strip()\n",
    "entitlements = lines[12].strip()\n",
    "\n",
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "    \"country\": country,\n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": place_of_birth.strip(),\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}\n",
    "\n",
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9259896a-2510-4cea-b3bd-74117585f7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U K DRIVING LICENCE',\n",
       " 'COLOMBARI',\n",
       " 'MR SAMUEL CHARLES',\n",
       " '20.02.1998 UNITED KINGDOM',\n",
       " '08.02.2022 4c. DVLA',\n",
       " '07.02.2027',\n",
       " 'COLOM902208SC9BH 33',\n",
       " '25 SOUTHGATE, HORNSEA, HU18 1RE',\n",
       " 'AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e61e01ef-1dbf-4f6a-9a14-db3d0dabffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U K DRIVING LICENCE', 'COLOMBARI', 'MR SAMUEL CHARLES', '20.02.1998 UNITED KINGDOM', '08.02.2022 4c. DVLA', '07.02.2027', 'COLOM902208SC9BH 33', '25 SOUTHGATE, HORNSEA, HU18 1RE', 'AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q']\n"
     ]
    }
   ],
   "source": [
    "lines = [line for line in lines if line.strip()]\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092d7ae-862c-4542-986f-a60637cf218c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32353f46-c70e-4e1f-aded-54389582c765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711e5ca-cc28-4fb1-93f2-502ca40dda37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bae149-6c42-40fe-882b-53ddd492b190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccb64e-2d31-4c73-89c7-1bbb823a6812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d65beb9-546e-45c8-8219-09b37a8926c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U K DRIVING LICENCE\\n\\nCOLOMBARI\\nMR SAMUEL CHARLES\\n\\n20.02.1998 UNITED KINGDOM\\n08.02.2022 4c. DVLA\\n07.02.2027\\nCOLOM902208SC9BH 33\\n\\n\\n\\n25 SOUTHGATE, HORNSEA, HU18 1RE\\n\\nAM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43fe827e-e672-4157-bb61-a365e96e2708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"United Kingdom\",\n",
      "    \"surname\": \"COLOMBARI\",\n",
      "    \"first_name\": \"MR SAMUEL CHARLES\",\n",
      "    \"date_of_birth\": \"20.02.1998\",\n",
      "    \"place_of_birth\": \"UNITED\",\n",
      "    \"date_of_issue\": \"08.02.2022\",\n",
      "    \"issuing_authority\": \"DVLA\",\n",
      "    \"expiry_date\": \"07.02.2027\",\n",
      "    \"driver_number\": \"AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\",\n",
      "    \"address\": \"\",\n",
      "    \"entitlements\": \"25 SOUTHGATE, HORNSEA, HU18 1RE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Extracted text\n",
    "extracted_text \n",
    "\n",
    "\n",
    "# Split the text into lines for easier parsing\n",
    "lines = extracted_text.strip().split('\\n')\n",
    "\n",
    "# Initialize dictionary fields\n",
    "country = \"\"\n",
    "surname = \"\"\n",
    "first_name = \"\"\n",
    "date_of_birth = \"\"\n",
    "place_of_birth = \"\"\n",
    "date_of_issue = \"\"\n",
    "issuing_authority = \"\"\n",
    "expiry_date = \"\"\n",
    "driver_number = \"\"\n",
    "address = \"\"\n",
    "entitlements = \"\"\n",
    "\n",
    "# Parse through the lines for relevant information\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Country\n",
    "    if \"UNITED KINGDOM\" in line:\n",
    "        country = \"United Kingdom\"\n",
    "    \n",
    "    # Name fields\n",
    "    if \"MR\" in line or \"MRS\" in line or \"MISS\" in line:\n",
    "        first_name = line\n",
    "    \n",
    "    # Date of birth and place of birth (usually in one line)\n",
    "    if \"UNITED KINGDOM\" in line:\n",
    "        parts = line.split(\" \")\n",
    "        date_of_birth = parts[0]\n",
    "        place_of_birth = parts[1]\n",
    "\n",
    "    # Date of issue and authority (contains \"4c.\")\n",
    "    if \"4c.\" in line:\n",
    "        issue_data = line.split(\" 4c. \")\n",
    "        date_of_issue = issue_data[0]\n",
    "        issuing_authority = issue_data[1]\n",
    "\n",
    "    # Expiry date\n",
    "    if i == 7:  # Expiry date comes after the line with issue details\n",
    "        expiry_date = line\n",
    "\n",
    "    # Driver number (usually the long alphanumeric string)\n",
    "    if len(line) > 15 and \" \" in line:\n",
    "        driver_number = line\n",
    "\n",
    "    # Address field\n",
    "    if i == 10:\n",
    "        address = line\n",
    "\n",
    "    # Entitlements\n",
    "    if i == 12:\n",
    "        entitlements = line\n",
    "\n",
    "# Create dictionary for the JSON format\n",
    "driving_licence_data = {\n",
    "    \"country\": country,\n",
    "    \"surname\": \"COLOMBARI\",  # Assuming this was parsed earlier correctly\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth,\n",
    "    \"place_of_birth\": place_of_birth,\n",
    "    \"date_of_issue\": date_of_issue,\n",
    "    \"issuing_authority\": issuing_authority,\n",
    "    \"expiry_date\": expiry_date,\n",
    "    \"driver_number\": driver_number,\n",
    "    \"address\": address,\n",
    "    \"entitlements\": entitlements\n",
    "}\n",
    "\n",
    "# Convert dictionary to JSON format\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the final JSON\n",
    "print(driving_licence_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "feb2dbd4-27eb-47b3-9e71-6734078e26e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m surname \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# Adjusted index for surname\u001b[39;00m\n\u001b[0;32m     15\u001b[0m first_name \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# Adjusted index for first name\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m date_of_birth, place_of_birth \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m UNITED KINGDOM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m date_of_issue, issuing_authority \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 4c. \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m expiry_date \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Identify the country from the text\n",
    "country = \"Unknown\"  # Default value\n",
    "for line in lines:\n",
    "    if \"UNITED KINGDOM\" in line.upper():  # Look for 'UNITED KINGDOM' in any line\n",
    "        country = \"United Kingdom\"\n",
    "    elif \"U K\" in line.upper():\n",
    "        country = \"United Kingdom\"\n",
    "\n",
    "# Parsing the text based on known structure\n",
    "surname = lines[1].strip()  # Adjusted index for surname\n",
    "first_name = lines[2].strip()  # Adjusted index for first name\n",
    "date_of_birth, place_of_birth = lines[3].strip().split(' UNITED KINGDOM')\n",
    "date_of_issue, issuing_authority = lines[4].strip().split(' 4c. ')\n",
    "expiry_date = lines[5].strip()\n",
    "driver_number = lines[6].strip()\n",
    "address = lines[7].strip()\n",
    "entitlements = lines[8].strip()\n",
    "\n",
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "    \"country\": country,\n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": place_of_birth.strip(),\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}\n",
    "\n",
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2878270a-9bf5-4071-9e0f-4b1fb1f8ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"United Kingdom\",\n",
      "    \"surname\": \"COLOMBARI\",\n",
      "    \"first_name\": \"MR SAMUEL CHARLES\",\n",
      "    \"date_of_birth\": \"20.02.1998\",\n",
      "    \"place_of_birth\": \"\",\n",
      "    \"date_of_issue\": \"08.02.2022\",\n",
      "    \"issuing_authority\": \"DVLA\",\n",
      "    \"expiry_date\": \"07.02.2027\",\n",
      "    \"driver_number\": \"COLOM902208SC9BH 33\",\n",
      "    \"address\": \"25 SOUTHGATE, HORNSEA, HU18 1RE\",\n",
      "    \"entitlements\": \"AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Identify the country from the text\n",
    "country = \"Unknown\"  # Default value\n",
    "for line in lines:\n",
    "    if \"UNITED KINGDOM\" in line.upper():  # Look for 'UNITED KINGDOM' in any line\n",
    "        country = \"United Kingdom\"\n",
    "    elif \"U K\" in line.upper():\n",
    "        country = \"United Kingdom\"\n",
    "\n",
    "# Parsing the text based on known structure\n",
    "surname = lines[1].strip()  # Adjusted index for surname\n",
    "first_name = lines[2].strip()  # Adjusted index for first name\n",
    "\n",
    "# Handle splitting date_of_birth and place_of_birth more robustly\n",
    "try:\n",
    "    date_of_birth, place_of_birth = lines[3].strip().split(' UNITED KINGDOM')\n",
    "except ValueError:\n",
    "    date_of_birth = lines[3].strip()\n",
    "    place_of_birth = \"Unknown\"\n",
    "\n",
    "# Handle splitting date_of_issue and issuing_authority more robustly\n",
    "try:\n",
    "    date_of_issue, issuing_authority = lines[4].strip().split(' 4c. ')\n",
    "except ValueError:\n",
    "    date_of_issue = lines[4].strip()\n",
    "    issuing_authority = \"Unknown\"\n",
    "\n",
    "expiry_date = lines[5].strip()\n",
    "driver_number = lines[6].strip()\n",
    "address = lines[7].strip()\n",
    "entitlements = lines[8].strip()\n",
    "\n",
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "    \"country\": country,\n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": place_of_birth.strip(),\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}\n",
    "\n",
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a7bc174-fce4-4261-ad82-cff008a174a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"United Kingdom\",\n",
      "    \"surname\": \"COLOMBARI\",\n",
      "    \"first_name\": \"SAMUEL CHARLES\",\n",
      "    \"date_of_birth\": \"20.02.1998\",\n",
      "    \"place_of_birth\": \"United Kingdom\",\n",
      "    \"date_of_issue\": \"08.02.2022\",\n",
      "    \"issuing_authority\": \"DVLA\",\n",
      "    \"expiry_date\": \"07.02.2027\",\n",
      "    \"driver_number\": \"COLOM902208SC9BH 33\",\n",
      "    \"address\": \"25 SOUTHGATE, HORNSEA, HU18 1RE\",\n",
      "    \"entitlements\": \"AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Updated list\n",
    "lines = [\n",
    "    'U K DRIVING LICENCE',\n",
    "    'COLOMBARI',\n",
    "    'MR SAMUEL CHARLES',\n",
    "    '20.02.1998 UNITED KINGDOM',\n",
    "    '08.02.2022 4c. DVLA',\n",
    "    '07.02.2027',\n",
    "    'COLOM902208SC9BH 33',\n",
    "    '25 SOUTHGATE, HORNSEA, HU18 1RE',\n",
    "    'AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q'\n",
    "]\n",
    "\n",
    "# Identify the country from the text\n",
    "country = \"Unknown\"  # Default value\n",
    "for line in lines:\n",
    "    if \"UNITED KINGDOM\" in line.upper():  # Look for 'UNITED KINGDOM' in any line\n",
    "        country = \"United Kingdom\"\n",
    "    elif \"U K\" in line.upper():\n",
    "        country = \"United Kingdom\"\n",
    "\n",
    "# Parsing the text based on known structure\n",
    "surname = lines[1].strip()  # Adjusted index for surname\n",
    "first_name = lines[2].strip()  # Adjusted index for first name\n",
    "\n",
    "# Handle splitting date_of_birth and place_of_birth more robustly\n",
    "date_of_birth_place = lines[3].strip().split(' UNITED KINGDOM')\n",
    "date_of_birth = date_of_birth_place[0].strip()\n",
    "place_of_birth = date_of_birth_place[1].strip() if len(date_of_birth_place) > 1 else \"Unknown\"\n",
    "\n",
    "# Handle splitting date_of_issue and issuing_authority more robustly\n",
    "date_of_issue_authority = lines[4].strip().split(' 4c. ')\n",
    "date_of_issue = date_of_issue_authority[0].strip()\n",
    "issuing_authority = date_of_issue_authority[1].strip() if len(date_of_issue_authority) > 1 else \"Unknown\"\n",
    "\n",
    "expiry_date = lines[5].strip()\n",
    "driver_number = lines[6].strip()\n",
    "address = lines[7].strip()\n",
    "entitlements = lines[8].strip()\n",
    "\n",
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "   \n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": country,\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}\n",
    "\n",
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5175ddb-867d-4d4e-b673-48c08c80f33c",
   "metadata": {},
   "source": [
    "#  'COLOMBARI',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4c59dce0-b4bf-4783-996e-286bf6760f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "U K DRIVING LICENCE\n",
      "\n",
      "COLOMBARI\n",
      "MR SAMUEL CHARLES\n",
      "\n",
      "20.02.1998 UNITED KINGDOM\n",
      "08.02.2022 4c. DVLA\n",
      "07.02.2027\n",
      "COLOM902208SC9BH 33\n",
      "\n",
      "Seu\n",
      "\n",
      "25 SOUTHGATE, HORNSEA, HU18 1RE\n",
      "\n",
      "AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure that Tesseract is correctly installed and the path is set (for Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update path as needed\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Extract text using pytesseract\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "# Path to the local image file\n",
    "image_path = \"F:/wesi/5.jpg\"\n",
    "\n",
    "try:\n",
    "    # Open the local image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    \n",
    "    # Output the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fec58fa8-285e-49db-a254-a139df889bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d2102cda-24a3-47cc-8d34-0846a6c78c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U K DRIVING LICENCE',\n",
       " '',\n",
       " 'COLOMBARI',\n",
       " 'MR SAMUEL CHARLES',\n",
       " '',\n",
       " '20.02.1998 UNITED KINGDOM',\n",
       " '08.02.2022 4c. DVLA',\n",
       " '07.02.2027',\n",
       " 'COLOM902208SC9BH 33',\n",
       " '',\n",
       " 'Seu',\n",
       " '',\n",
       " '25 SOUTHGATE, HORNSEA, HU18 1RE',\n",
       " '',\n",
       " 'AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the text into lines for easier parsing\n",
    "lines = extracted_text.strip().split('\\n')\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8bb61bca-522e-4f9d-9149-ff6298b14128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = [line for line in extracted_text if line.strip()]\n",
    "\n",
    "# print(lines)\n",
    "# Remove empty strings from the list\n",
    "lines = [line for line in lines if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c4938336-407c-4410-b57d-5507e5af8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "77ec81ce-6c5f-47e4-86dd-54bd7ca6e192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U K DRIVING LICENCE',\n",
       " 'COLOMBARI',\n",
       " 'MR SAMUEL CHARLES',\n",
       " '20.02.1998 UNITED KINGDOM',\n",
       " '08.02.2022 4c. DVLA',\n",
       " '07.02.2027',\n",
       " 'COLOM902208SC9BH 33',\n",
       " '25 SOUTHGATE, HORNSEA, HU18 1RE',\n",
       " 'AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4161629c-c45a-44f2-877d-788c74ee294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"surname\": \"COLOMBARI\",\n",
      "    \"first_name\": \"MR SAMUEL CHARLES\",\n",
      "    \"date_of_birth\": \"20.02.1998\",\n",
      "    \"place_of_birth\": \"United Kingdom\",\n",
      "    \"date_of_issue\": \"08.02.2022\",\n",
      "    \"issuing_authority\": \"DVLA\",\n",
      "    \"expiry_date\": \"07.02.2027\",\n",
      "    \"driver_number\": \"COLOM902208SC9BH 33\",\n",
      "    \"address\": \"25 SOUTHGATE, HORNSEA, HU18 1RE\",\n",
      "    \"entitlements\": \"AM/B/C 1/D 1/D/BE/D1E/DE/f/k/q\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Extracting values from the list\n",
    "surname = lines[1].strip()\n",
    "first_name = lines[2].strip()\n",
    "date_of_birth, place_of_birth = lines[3].strip().split(' UNITED KINGDOM')\n",
    "place_of_birth = \"United Kingdom\"  # Directly set to \"United Kingdom\"\n",
    "date_of_issue, issuing_authority = lines[4].strip().split(' 4c. ')\n",
    "expiry_date = lines[5].strip()\n",
    "driver_number = lines[6].strip()\n",
    "address = lines[7].strip()\n",
    "entitlements = lines[8].strip()\n",
    "\n",
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": place_of_birth.strip(),\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}\n",
    "\n",
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75cabb6-f037-4129-a8f0-4cc4b59c4af4",
   "metadata": {},
   "source": [
    "# diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a290d11a-9b3e-44ca-94cd-9d761f988a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "( DRIVING LICENCE\n",
      "\n",
      "NICOL\n",
      "MR SCOTT ALEXANDER\n",
      "\n",
      "16.04.1999 UNITED KINGDOM <\n",
      "\n",
      ". 23.02.2022 4c. DVLA :\n",
      "\n",
      "22022032 |\n",
      "NICOL904169SA9WL 4 G4 sl\n",
      "29E MAPLE DRIVE JOHNSTONE Pas 9Sx Sos 3\n",
      "\n",
      "sieeniaetle i\n",
      "\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure that Tesseract is correctly installed and the path is set (for Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update path as needed\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Extract text using pytesseract\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "# Path to the local image file\n",
    "image_path = \"F:/wesi/nicolone.jpg\"\n",
    "\n",
    "try:\n",
    "    # Open the local image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    \n",
    "    # Output the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "313e9f26-5322-4fa5-9425-060e12925493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( DRIVING LICENCE\\n\\nNICOL\\nMR SCOTT ALEXANDER\\n\\n16.04.1999 UNITED KINGDOM <\\n\\n. 23.02.2022 4c. DVLA :\\n\\n22022032 |\\nNICOL904169SA9WL 4 G4 sl\\n29E MAPLE DRIVE JOHNSTONE Pas 9Sx Sos 3\\n\\nsieeniaetle i\\n\\n|\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24ba01b6-a012-4ebd-a918-95d318a70739",
   "metadata": {},
   "outputs": [],
   "source": [
    " extracted_lines = extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f606f9f4-27bf-429e-8898-12325175f65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( DRIVING LICENCE\\n\\nNICOL\\nMR SCOTT ALEXANDER\\n\\n16.04.1999 UNITED KINGDOM <\\n\\n. 23.02.2022 4c. DVLA :\\n\\n22022032 |\\nNICOL904169SA9WL 4 G4 sl\\n29E MAPLE DRIVE JOHNSTONE Pas 9Sx Sos 3\\n\\nsieeniaetle i\\n\\n|\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a5a8d6aa-e62a-424b-b86d-2f270baca001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['( DRIVING LICENCE',\n",
       " '',\n",
       " 'NICOL',\n",
       " 'MR SCOTT ALEXANDER',\n",
       " '',\n",
       " '16.04.1999 UNITED KINGDOM <',\n",
       " '',\n",
       " '. 23.02.2022 4c. DVLA :',\n",
       " '',\n",
       " '22022032 |',\n",
       " 'NICOL904169SA9WL 4 G4 sl',\n",
       " '29E MAPLE DRIVE JOHNSTONE Pas 9Sx Sos 3',\n",
       " '',\n",
       " 'sieeniaetle i',\n",
       " '',\n",
       " '|']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the text into lines for easier parsing\n",
    "lines = extracted_lines.strip().split('\\n')\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6460a25c-f458-4b27-9f59-e302c4c269b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"surname\": \"\",\n",
      "    \"first_name\": \"\",\n",
      "    \"date_of_birth\": \"\",\n",
      "    \"place_of_birth\": \"\",\n",
      "    \"date_of_issue\": \"\",\n",
      "    \"issuing_authority\": \"\",\n",
      "    \"expiry_date\": \"\",\n",
      "    \"driver_number\": \"\",\n",
      "    \"address\": \",\",\n",
      "    \"entitlements\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Example extracted text lines\n",
    "\n",
    "\n",
    "# Define the section markers for the relevant parts\n",
    "section_markers = {\n",
    "    'surname': 1,\n",
    "    'first_name': 2,\n",
    "    'date_of_birth': 3,\n",
    "    'date_of_issue': 4,\n",
    "    'expiry_date': 5,\n",
    "    'driver_number': 6,\n",
    "    'address': 8,\n",
    "    'entitlements': 9\n",
    "}\n",
    "\n",
    "# Extracting values from the list based on the markers\n",
    "def extract_value(lines, marker):\n",
    "    # Adjust for 0-based indexing\n",
    "    index = marker - 1\n",
    "    if 0 <= index < len(lines):\n",
    "        line = lines[index]\n",
    "        if '. ' in line:\n",
    "            return line.split('. ', 1)[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "# Extract values using the defined markers\n",
    "surname = extract_value(extracted_lines, section_markers['surname'])\n",
    "first_name = extract_value(extracted_lines, section_markers['first_name'])\n",
    "date_of_birth_line = extract_value(extracted_lines, section_markers['date_of_birth'])\n",
    "date_of_birth, place_of_birth = date_of_birth_line.split(' UNITED KINGDOM') if ' UNITED KINGDOM' in date_of_birth_line else (date_of_birth_line, \"\")\n",
    "date_of_issue, issuing_authority = extract_value(extracted_lines, section_markers['date_of_issue']).split(' 4c ', 1) if ' 4c ' in extract_value(extracted_lines, section_markers['date_of_issue']) else (extract_value(extracted_lines, section_markers['date_of_issue']), \"\")\n",
    "expiry_date = extract_value(extracted_lines, section_markers['expiry_date']).split(' ;')[0]\n",
    "driver_number = extract_value(extracted_lines, section_markers['driver_number'])\n",
    "address = f\"{extract_value(extracted_lines, section_markers['address'])}, {extracted_lines[section_markers['address'] + 1].strip()}\"\n",
    "entitlements = extract_value(extracted_lines, section_markers['entitlements'])\n",
    "\n",
    "# Mapping the parsed data to the structured dictionary\n",
    "driving_licence_data = {\n",
    "    \"surname\": surname,\n",
    "    \"first_name\": first_name,\n",
    "    \"date_of_birth\": date_of_birth.strip(),\n",
    "    \"place_of_birth\": place_of_birth.strip(),\n",
    "    \"date_of_issue\": date_of_issue.strip(),\n",
    "    \"issuing_authority\": issuing_authority.strip(),\n",
    "    \"expiry_date\": expiry_date.strip(),\n",
    "    \"driver_number\": driver_number.strip(),\n",
    "    \"address\": address.strip(),\n",
    "    \"entitlements\": entitlements.strip()\n",
    "}\n",
    "\n",
    "# Converting dictionary to JSON\n",
    "driving_licence_json = json.dumps(driving_licence_data, indent=4)\n",
    "\n",
    "# Output the JSON format\n",
    "print(driving_licence_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "188fc198-3ffb-4fb1-822b-e7b77ca3dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Specific Lines:\n",
      "1. HULCOME O'BRIEN\n",
      "2. MISS AKHIRAH JANAN NN\n",
      "3. 02.10.1995 UNITED KINGDOM\n",
      "5. HULCO960025AJ9FH 07\n",
      "8. FLAT 17, SHALDEN HOUSE, TUNWORTH\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract specific lines\n",
    "def extract_specific_lines(text):\n",
    "    # Define the points we want to extract\n",
    "    points_to_extract = {'1', '2', '3', '4a', '4b','4c', '5', '8'}\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Initialize an empty list for the relevant lines\n",
    "    relevant_lines = []\n",
    "    \n",
    "    # Iterate over lines to extract relevant ones\n",
    "    for line in lines:\n",
    "        # Extract the point number from the line\n",
    "        match = re.match(r'^(\\d+|[a-z]+)\\.', line.strip())\n",
    "        if match:\n",
    "            point_number = match.group(1)\n",
    "            if point_number in points_to_extract:\n",
    "                relevant_lines.append(line.strip())\n",
    "    \n",
    "    return '\\n'.join(relevant_lines)\n",
    "\n",
    "# Extract specific lines\n",
    "result = extract_specific_lines(extracted_text)\n",
    "\n",
    "# Output the result\n",
    "print(\"Extracted Specific Lines:\")\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27288543-4b05-4b5f-bd44-9d462b270cea",
   "metadata": {},
   "source": [
    "# one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7145645c-c247-4ad6-8c3c-3ddc805807e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "NS toto\n",
      "\n",
      "1 Ra el Wad dade dak\n",
      "\n",
      "eat oh ae ae oe\n",
      "\n",
      "Tees ee eee eS\n",
      "\n",
      "â€˜Chee eee ceee sea\n",
      "oa teal fi\n",
      "\n",
      "he eat a ne\n",
      "Rati eee Gane ee ad\n",
      "}\n",
      "\n",
      "RES tne\n",
      "\n",
      "Ph orer ase\n",
      "A eas\n",
      "\n",
      "sana coma eel\n",
      "t49+d43034)\n",
      "RAT AAA\n",
      "TR\n",
      "\n",
      "Hat abd 8 $4)\n",
      "\n",
      "tah tet eka 4\n",
      "Mette\n",
      "RET fh\n",
      "A ey hl\n",
      "Revie chicas att)\n",
      "eet: Ew)\n",
      "\"Sey bake bite te, ateeiis\n",
      "meas hag\n",
      "SNe oat\n",
      "Siete alt tare Yaa has\n",
      "\n",
      "eos e See CaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure that Tesseract is correctly installed and the path is set (for Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update path as needed\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Extract text using pytesseract\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "# Path to the local image file\n",
    "image_path = \"F:/wesi/nicol.jpg\"\n",
    "\n",
    "try:\n",
    "    # Open the local image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    \n",
    "    # Output the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9f073359-bcd7-4f9d-af73-7c72d204d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "( DRIVING LICENCE\n",
      "\n",
      "NICOL\n",
      "MR SCOTT ALEXANDER\n",
      "\n",
      "16.04.1999 UNITED KINGDOM <\n",
      "\n",
      ". 23.02.2022 4c. DVLA :\n",
      "\n",
      "22022032 |\n",
      "NICOL904169SA9WL 4 G4 sl\n",
      "29E MAPLE DRIVE JOHNSTONE Pas 9Sx Sos 3\n",
      "\n",
      "sieeniaetle i\n",
      "\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure that Tesseract is correctly installed and the path is set (for Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update path as needed\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Extract text using pytesseract\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "# Path to the local image file\n",
    "image_path = \"F:/wesi/nicolone.jpg\"\n",
    "\n",
    "try:\n",
    "    # Open the local image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    \n",
    "    # Output the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ae7ed49f-0992-43f7-8c77-be98e4cec1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "DRIVING LICENCE - TRWYDDEL\n",
      "\n",
      "i. WILLIAMS\n",
      "2. MR GERAINT LLEWELLYN .\n",
      "\n",
      "wre\n",
      "\n",
      "3. 30.01.1981 WALES\n",
      "42. 02.05.2019 4c. DVLA SS\n",
      "4b. 01.05.2029\n",
      "\n",
      "a â€”\n",
      "5.  WILLI801301GL9PD 10 ah\n",
      "\n",
      "i il /\n",
      "@. 3 OAKDALE VIEW, CENTRAL AVENUE, OAKDALE\n",
      ": BLACKWOOD. NP12 OFB\n",
      "\n",
      "Cor ants eT cdi a ei f\n",
      "0 Big OOS ET OEE GMT te os od Â© SA ag\n",
      "Mos ee oe yee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Ensure that Tesseract is correctly installed and the path is set (for Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update path as needed\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        # Extract text using pytesseract\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {str(e)}\"\n",
    "\n",
    "# Path to the local image file\n",
    "image_path = \"F:/wesi/8.jpg\"\n",
    "\n",
    "try:\n",
    "    # Open the local image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Extract text from the image\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    \n",
    "    # Output the extracted text\n",
    "    print(\"Extracted Text:\")\n",
    "    print(extracted_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error opening image: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a04d4c55-06d3-44aa-ba00-68677d671328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Specific Lines:\n",
      "i. WILLIAMS\n",
      "2. MR GERAINT LLEWELLYN .\n",
      "3. 30.01.1981 WALES\n",
      "42. 02.05.2019 4c. DVLA SS\n",
      "4b. 01.05.2029\n",
      "5.  WILLI801301GL9PD 10 ah\n",
      "i il /\n",
      "@. 3 OAKDALE VIEW, CENTRAL AVENUE, OAKDALE\n",
      ": BLACKWOOD. NP12 OFB\n",
      "Cor ants eT cdi a ei f\n",
      "0 Big OOS ET OEE GMT te os od Â© SA ag\n",
      "Mos ee oe yee\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract specific lines\n",
    "def extract_specific_lines(text):\n",
    "    # Define the points we want to extract\n",
    "    points_to_extract = {'i', '2', '3', '42', '4b', '5', '@'}\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Initialize an empty list for the relevant lines\n",
    "    relevant_lines = []\n",
    "    \n",
    "    # Flag to include lines after point 5, up to specific content if needed\n",
    "    include_after_point_5 = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check for line starting with a point number or special character\n",
    "        match = re.match(r'^([a-zA-Z0-9]+|[a-z]+)\\.', line.strip())\n",
    "        if match:\n",
    "            point_number = match.group(1)\n",
    "            if point_number in points_to_extract:\n",
    "                relevant_lines.append(line.strip())\n",
    "                if point_number == '5':\n",
    "                    include_after_point_5 = True\n",
    "            elif include_after_point_5 and point_number == '@':\n",
    "                relevant_lines.append(line.strip())\n",
    "                break\n",
    "        elif include_after_point_5:\n",
    "            # Include lines after point 5 until the special character\n",
    "            if not line.strip():  # Skip empty lines\n",
    "                continue\n",
    "            relevant_lines.append(line.strip())\n",
    "    \n",
    "    return '\\n'.join(relevant_lines)\n",
    "\n",
    "# Extract specific lines\n",
    "result = extract_specific_lines(extracted_text)\n",
    "\n",
    "# Output the result\n",
    "print(\"Extracted Specific Lines:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "874c3df1-c3b5-4d28-904a-8eada8d9f3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Specific Lines:\n",
      "2. MR GERAINT LLEWELLYN .\n",
      "3. 30.01.1981 WALES\n",
      "5.  WILLI801301GL9PD 10 ah\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract specific lines\n",
    "def extract_specific_lines(text):\n",
    "    # Define the points we want to extract\n",
    "    points_to_extract = {'1', '2', '3', '4a', '4b','4c', '5', '8'}\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Initialize an empty list for the relevant lines\n",
    "    relevant_lines = []\n",
    "    \n",
    "    # Iterate over lines to extract relevant ones\n",
    "    for line in lines:\n",
    "        # Extract the point number from the line\n",
    "        match = re.match(r'^(\\d+|[a-z]+)\\.', line.strip())\n",
    "        if match:\n",
    "            point_number = match.group(1)\n",
    "            if point_number in points_to_extract:\n",
    "                relevant_lines.append(line.strip())\n",
    "    \n",
    "    return '\\n'.join(relevant_lines)\n",
    "\n",
    "# Extract specific lines\n",
    "result = extract_specific_lines(extracted_text)\n",
    "\n",
    "# Output the result\n",
    "print(\"Extracted Specific Lines:\")\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ba69f-2a9f-4317-9054-8c9e7d0c8080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
